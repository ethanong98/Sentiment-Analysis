{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>The finale of the Weissmuller Tarzan movies is...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40667</th>\n",
       "      <td>When an actor has to play the role of an actor...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43871</th>\n",
       "      <td>I saw an early screening of this film in New Y...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44680</th>\n",
       "      <td>I read the novel some years ago and I liked it...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16236</th>\n",
       "      <td>I admit not being that fond of Oliver! as a yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7687</th>\n",
       "      <td>Watched this as a late TV movie last night pur...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49899</th>\n",
       "      <td>After realizing what is going on around us ......</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33220</th>\n",
       "      <td>The storyline of \"The Stranger\" mirrors somewh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37719</th>\n",
       "      <td>This is by far the funniest short made by the ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9417</th>\n",
       "      <td>Oz is the TV show which is intensive non-stop ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "6164   The finale of the Weissmuller Tarzan movies is...  negative\n",
       "40667  When an actor has to play the role of an actor...  positive\n",
       "43871  I saw an early screening of this film in New Y...  negative\n",
       "44680  I read the novel some years ago and I liked it...  negative\n",
       "16236  I admit not being that fond of Oliver! as a yo...  positive\n",
       "7687   Watched this as a late TV movie last night pur...  positive\n",
       "49899  After realizing what is going on around us ......  positive\n",
       "33220  The storyline of \"The Stranger\" mirrors somewh...  negative\n",
       "37719  This is by far the funniest short made by the ...  positive\n",
       "9417   Oz is the TV show which is intensive non-stop ...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading dataframe\n",
    "data = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make 0 represent negative and 1 represent positive reivews\n",
    "data['label'] = data['sentiment'].replace(['positive', 'negative'],['1', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39503</th>\n",
       "      <td>This movie was recommended to me by several pe...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37576</th>\n",
       "      <td>We all enjoyed the movie. It is a very charmin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10307</th>\n",
       "      <td>I keep waiting for Peter Fonda to start acting...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>This movie is even a big step down form the ty...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17917</th>\n",
       "      <td>Minnie and Moskowitz is the most pathetic and ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14874</th>\n",
       "      <td>I fell in love with Emily Watson in Breaking t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36168</th>\n",
       "      <td>Many have disparaged Never Say Never Again bec...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>Absolutely unwatchable, lowest quality film ma...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11161</th>\n",
       "      <td>When I went to the cinema, I expected not much...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43885</th>\n",
       "      <td>Hidden Frontier is notable for being the longe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment label\n",
       "39503  This movie was recommended to me by several pe...  negative     0\n",
       "37576  We all enjoyed the movie. It is a very charmin...  positive     1\n",
       "10307  I keep waiting for Peter Fonda to start acting...  negative     0\n",
       "8911   This movie is even a big step down form the ty...  negative     0\n",
       "17917  Minnie and Moskowitz is the most pathetic and ...  positive     1\n",
       "14874  I fell in love with Emily Watson in Breaking t...  positive     1\n",
       "36168  Many have disparaged Never Say Never Again bec...  positive     1\n",
       "6781   Absolutely unwatchable, lowest quality film ma...  negative     0\n",
       "11161  When I went to the cinema, I expected not much...  positive     1\n",
       "43885  Hidden Frontier is notable for being the longe...  positive     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    25000\n",
       "0    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'C:\\Users\\ethan\\OneDrive\\Desktop\\092023 SEM\\NLP\\\\Assignment\\Assignment 1\\IMDB_Dataset_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Preprocessing for sentiment analysis\n",
    "import string\n",
    "import emoji\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.metrics import edit_distance\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    #1. Generating the list of words in the tweet (hastags and other punctuations removed)\n",
    "    text_blob = TextBlob(text)\n",
    "    text = ' '.join(text_blob.words)\n",
    "    \n",
    "    #2. clean the number \n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    \n",
    "    #3. lower the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    #4. conver the emoji to text form\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    #5. remove punctuation \n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    \n",
    "    #6. tokenize the text\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    #7. remove empty token\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    \n",
    "    #8. remove non-alphabetical token\n",
    "    text = [t for t in text if t.isalpha()]\n",
    "    \n",
    "    #9. replace the negation token\n",
    "    replacer  = AntonymReplacer()\n",
    "    text = replacer.replace_negations(text)\n",
    "    \n",
    "    #10. remove the stopwords\n",
    "    text = [i for i in text if i not in stopwords]\n",
    "    \n",
    "    #11. stem the text\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    text = [porter_stemmer.stem(w) for w in text]\n",
    "    \n",
    "    return text\n",
    "\n",
    "class AntonymReplacer(object):\n",
    "    def replace(self, word, pos=None):\n",
    "        antonyms = set()\n",
    "\n",
    "        for syn in wordnet.synsets(word, pos=pos):\n",
    "            for lemma in syn.lemmas():\n",
    "                for antonym in lemma.antonyms():\n",
    "                    antonyms.add(antonym.name())\n",
    "\n",
    "        if len(antonyms) == 1:\n",
    "            return antonyms.pop()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def replace_negations(self, sent):\n",
    "        i, l = 0, len(sent)\n",
    "        words = []\n",
    "\n",
    "        while i < l:\n",
    "            word = sent[i]\n",
    "\n",
    "            if word == 'not' and i+1 < l:\n",
    "                ant = self.replace(sent[i+1])\n",
    "\n",
    "                if ant:\n",
    "                    words.append(ant)\n",
    "                    i += 2\n",
    "                    continue\n",
    "\n",
    "            words.append(word)\n",
    "            i += 1\n",
    "\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So im not a big fan of Boll's work but then again not many are. I enjoyed his movie Postal (maybe im the only one). Boll apparently bought the rights to use Far Cry long ago even before the game itself was even finsished. <br /><br />People who have enjoyed killing mercs and infiltrating secret research labs located on a tropical island should be warned, that this is not Far Cry... This is something Mr Boll have schemed together along with his legion of schmucks.. Feeling loneley on the set Mr Boll invites three of his countrymen to play with. These players go by the names of Til Schweiger, Udo Kier and Ralf Moeller.<br /><br />Three names that actually have made them selfs pretty big in the movie biz. So the tale goes like this, Jack Carver played by Til Schweiger (yes Carver is German all hail the bratwurst eating dudes!!) However I find that Tils acting in this movie is pretty badass.. People have complained about how he's not really staying true to the whole Carver agenda but we only saw carver in a first person perspective so we don't really know what he looked like when he was kicking a**.. <br /><br />However, the storyline in this film is beyond demented. We see the evil mad scientist Dr. Krieger played by Udo Kier, making Genetically-Mutated-soldiers or GMS as they are called. Performing his top-secret research on an island that reminds me of \"SPOILER\" Vancouver for some reason. Thats right no palm trees here. Instead we got some nice rich lumberjack-woods. We haven't even gone FAR before I started to CRY (mehehe) I cannot go on any more.. If you wanna stay true to Bolls shenanigans then go and see this movie you will not be disappointed it delivers the true Boll experience, meaning most of it will suck.<br /><br />There are some things worth mentioning that would imply that Boll did a good work on some areas of the film such as some nice boat and fighting scenes. Until the whole cromed/albino GMS squad enters the scene and everything just makes me laugh.. The movie Far Cry reeks of scheisse (that's poop for you simpletons) from a fa,r if you wanna take a wiff go ahead.. BTW Carver gets a very annoying sidekick who makes you wanna shoot him the first three minutes he's on screen.\n",
      "['im', 'big', 'fan', 'boll', 'work', 'enjoy', 'movi', 'postal', 'mayb', 'im', 'one', 'boll', 'appar', 'bought', 'right', 'use', 'far', 'cri', 'long', 'ago', 'even', 'game', 'even', 'finsish', 'br', 'br', 'peopl', 'enjoy', 'kill', 'merc', 'infiltr', 'secret', 'research', 'lab', 'locat', 'tropic', 'island', 'warn', 'near', 'cri', 'someth', 'mr', 'boll', 'scheme', 'togeth', 'along', 'legion', 'schmuck', 'feel', 'loneley', 'set', 'mr', 'boll', 'invit', 'three', 'countrymen', 'play', 'player', 'go', 'name', 'til', 'schweiger', 'udo', 'kier', 'ralf', 'moeller', 'br', 'br', 'three', 'name', 'actual', 'made', 'self', 'pretti', 'big', 'movi', 'biz', 'tale', 'goe', 'like', 'jack', 'carver', 'play', 'til', 'schweiger', 'ye', 'carver', 'german', 'hail', 'bratwurst', 'eat', 'dude', 'howev', 'find', 'til', 'act', 'movi', 'pretti', 'badass', 'peopl', 'complain', 'realli', 'stay', 'true', 'whole', 'carver', 'agenda', 'saw', 'carver', 'first', 'person', 'perspect', 'nt', 'realli', 'know', 'look', 'like', 'kick', 'br', 'br', 'howev', 'storylin', 'film', 'beyond', 'dement', 'see', 'evil', 'mad', 'scientist', 'dr', 'krieger', 'play', 'udo', 'kier', 'make', 'geneticallymutatedsoldi', 'gm', 'call', 'perform', 'topsecret', 'research', 'island', 'remind', 'spoiler', 'vancouv', 'reason', 'that', 'right', 'palm', 'tree', 'instead', 'got', 'nice', 'rich', 'lumberjackwood', 'nt', 'even', 'gone', 'far', 'start', 'cri', 'meheh', 'go', 'wan', 'na', 'stay', 'true', 'boll', 'shenanigan', 'go', 'see', 'movi', 'differ', 'disappoint', 'deliv', 'true', 'boll', 'experi', 'mean', 'suck', 'br', 'br', 'thing', 'worth', 'mention', 'would', 'impli', 'boll', 'good', 'work', 'area', 'film', 'nice', 'boat', 'fight', 'scene', 'whole', 'cromedalbino', 'gm', 'squad', 'enter', 'scene', 'everyth', 'make', 'laugh', 'movi', 'far', 'cri', 'reek', 'scheiss', 'poop', 'simpleton', 'fa', 'r', 'wan', 'na', 'take', 'wiff', 'go', 'ahead', 'btw', 'carver', 'get', 'annoy', 'sidekick', 'make', 'wan', 'na', 'shoot', 'first', 'three', 'minut', 'screen']\n"
     ]
    }
   ],
   "source": [
    "print(data['review'].iloc[12])\n",
    "print(preprocess(data['review'].iloc[12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\"\"\"\n",
    "min_df=2, discard words appearing in less than 2 documents\n",
    "max_df=0.9, discard words appering in more than 90% of the documents\n",
    "sublinear_tf=True, use sublinear weighting\n",
    "use_idf=True, enable IDF\n",
    "\"\"\"\n",
    "vec = TfidfVectorizer(\n",
    "    analyzer=preprocess,\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True,\n",
    "    use_idf=True\n",
    ")\n",
    "\n",
    "tfidf_model = vec.fit(data['review'])\n",
    "train_vec = vec.transform(data['review'])\n",
    "\n",
    "#save vectorizer\n",
    "vectorizer_file = r'C:\\Users\\ethan\\OneDrive\\Desktop\\092023 SEM\\NLP\\Assignment\\Assignment 1\\ModelFolder/tfidf_vectorizer.sav';\n",
    "pickle.dump(tfidf_model, open(vectorizer_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 44622)\t0.051051921991970436\n",
      "  (0, 44535)\t0.09234484225013369\n",
      "  (0, 43743)\t0.03280097979657562\n",
      "  (0, 43533)\t0.06123646425193938\n",
      "  (0, 43048)\t0.15267635106300764\n",
      "  (0, 42973)\t0.05252362389325301\n",
      "  (0, 42501)\t0.041614436536244026\n",
      "  (0, 41939)\t0.12136572627028748\n",
      "  (0, 41672)\t0.08914544599409176\n",
      "  (0, 41191)\t0.044863711267744806\n",
      "  (0, 41078)\t0.07662586879126554\n",
      "  (0, 40597)\t0.059814263228259903\n",
      "  (0, 40211)\t0.11349753657676434\n",
      "  (0, 39850)\t0.035159489203875856\n",
      "  (0, 39718)\t0.07912507567426838\n",
      "  (0, 39304)\t0.0705968807711694\n",
      "  (0, 38728)\t0.08264214651353383\n",
      "  (0, 38216)\t0.15395936198492918\n",
      "  (0, 38128)\t0.06619523576894111\n",
      "  (0, 37707)\t0.0627814143259084\n",
      "  (0, 37654)\t0.08492905949150271\n",
      "  (0, 36857)\t0.08949552918897383\n",
      "  (0, 36261)\t0.07212140727476048\n",
      "  (0, 35930)\t0.058587962965835544\n",
      "  (0, 35787)\t0.08791749541271658\n",
      "  :\t:\n",
      "  (49999, 21263)\t0.20837045635142148\n",
      "  (49999, 19570)\t0.1629510683026242\n",
      "  (49999, 19169)\t0.1094291879482535\n",
      "  (49999, 19057)\t0.18670801891423458\n",
      "  (49999, 18469)\t0.09398898325826642\n",
      "  (49999, 17796)\t0.11029447689813254\n",
      "  (49999, 17085)\t0.14446820670892452\n",
      "  (49999, 15911)\t0.17854778145218228\n",
      "  (49999, 15867)\t0.058565252270022065\n",
      "  (49999, 13124)\t0.16688894539312332\n",
      "  (49999, 13072)\t0.16248786515911026\n",
      "  (49999, 12760)\t0.16661373503269328\n",
      "  (49999, 12526)\t0.10469496912989391\n",
      "  (49999, 12280)\t0.1172145157574019\n",
      "  (49999, 8631)\t0.18019822086171114\n",
      "  (49999, 6507)\t0.06276555395547455\n",
      "  (49999, 6478)\t0.14582964694683623\n",
      "  (49999, 6452)\t0.12320969673851626\n",
      "  (49999, 5556)\t0.16713634492829904\n",
      "  (49999, 5541)\t0.09245133291157791\n",
      "  (49999, 4704)\t0.0773298002927745\n",
      "  (49999, 3594)\t0.07868928060981083\n",
      "  (49999, 2429)\t0.12878010758723066\n",
      "  (49999, 1977)\t0.12185699178401564\n",
      "  (49999, 1433)\t0.08751927582706982\n"
     ]
    }
   ],
   "source": [
    "print(train_vec) #(Document number, word index number)       IDF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (40000, 45394)\n",
      "X_test shape: (10000, 45394)\n",
      "y_train shape: (40000,)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 4000\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_vec, \n",
    "                                            data.label, test_size=0.2, random_state=SEED)\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('y_test shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of SVM\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      4875\n",
      "           1       0.91      0.89      0.90      5125\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      " [[4435  440]\n",
      " [ 571 4554]]\n",
      "\n",
      "\n",
      "Accuracy score:  0.8989\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "clf_svm = SVC()\n",
    "\n",
    "clf_names = ['SVM']\n",
    "\n",
    "clf_types = [clf_svm]\n",
    "\n",
    "for (i, clf) in enumerate(clf_types):\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "    print('Result of {}\\n'.format(clf_names[i]))\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(classification_report(predictions, y_test))\n",
    "    print('\\n')\n",
    "    print('Confusion matrix: \\n', confusion_matrix(predictions, y_test))\n",
    "    print('\\n')\n",
    "    print('Accuracy score: ', accuracy_score(predictions, y_test))\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'C:\\Users\\ethan\\OneDrive\\Desktop\\092023 SEM\\NLP\\Assignment\\Assignment 1\\ModelFolder\\SVM_sentiment_model.sav'\n",
    "pickle.dump(clf_svm, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
